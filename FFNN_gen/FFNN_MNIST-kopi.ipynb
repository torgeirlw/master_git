{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be01ce8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "260f362e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a152aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                                transforms.Normalize((0.5), (0.5))\n",
    "                               ])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.FashionMNIST('MNIST_data/', download = True, train = True, transform = transform)\n",
    "testset = datasets.FashionMNIST('MNIST_data/', download = True, train = True, transform = transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = 64, shuffle = True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = 64, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13c46afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "# Examine a sample\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "print(type(images))\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "565d1c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fae6cfdac40>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[1].numpy().squeeze(), cmap = 'Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "257c7bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[1].numpy().squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbde0c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "542a6fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "portion_size = (10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70730c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = random.randint(0, images[1].shape[1]-portion_size[0]-1)\n",
    "y1 = random.randint(0, images[1].shape[2]-portion_size[1]-1)\n",
    "\n",
    "#x2, y2 = x1+portion_size[0]-1, y1+portion_size[1]-1\n",
    "x2, y2 = x1+portion_size[0], y1+portion_size[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "049f7efc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "915fe923",
   "metadata": {},
   "outputs": [],
   "source": [
    "part_im = images[1].numpy().squeeze()[x1:x2,y1:y2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5f1b11f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.99215686, -1.        , -1.        , -1.        , -0.9607843 ,\n",
       "        -0.42745095, -0.9607843 , -0.17647058,  0.8901961 ,  0.0196079 ],\n",
       "       [-1.        , -0.9843137 , -1.        , -0.78039217, -0.12941176,\n",
       "         0.10588241, -0.05098039,  0.15294123, -0.21568626, -1.        ],\n",
       "       [-0.99215686, -0.9764706 , -1.        ,  0.38823533,  0.85882354,\n",
       "        -0.5921569 ,  0.33333337, -0.23137254, -0.92941177, -1.        ],\n",
       "       [-1.        , -1.        , -1.        ,  0.48235297,  1.        ,\n",
       "        -0.08235294, -0.19999999, -0.05098039, -0.3490196 , -1.        ],\n",
       "       [-1.        , -1.        , -1.        ,  0.70980394,  0.9764706 ,\n",
       "         0.6392157 ,  0.32549024,  0.47450984,  0.7176471 , -0.8509804 ],\n",
       "       [ 0.13725495, -0.27843136, -0.654902  ,  0.01176476,  0.41960788,\n",
       "         0.6392157 ,  0.7176471 ,  0.6627451 ,  0.92156863,  0.07450986],\n",
       "       [-0.05882353,  0.2313726 ,  0.30980396,  0.01176476, -0.11372548,\n",
       "        -0.03529412,  0.30196083,  0.4431373 ,  0.23921573, -0.7490196 ],\n",
       "       [-1.        , -1.        , -0.94509804, -0.827451  , -0.5921569 ,\n",
       "        -0.44313723, -0.3490196 , -0.1607843 , -0.3960784 , -0.27058822],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -0.52156866],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e570bb62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 23, 3, 13)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1,x2,y1,y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd24a143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fae6d2c8400>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(part_im, cmap = 'Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29a52917",
   "metadata": {},
   "outputs": [],
   "source": [
    "part_im = part_im.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86e688e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part_im[:95].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90642e14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20ec6a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3668ea10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbc2a98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56b26913",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make dataloader that can sample part of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92e08b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make custum gaussian mixture NLL loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a4546db",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_imgs = torch.load('MNIST_data/FashionMNIST/processed/test.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b130300b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "08705077",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionNeihgborhoodData(Dataset):\n",
    "\n",
    "    def __init__(self, image_dir, transform=None, nbh_size=(4,9)):#csv_file,root,\n",
    "        #self.root = root\n",
    "        self.image_dir = image_dir\n",
    "        #self.image_files = os.listdir(image_dir)\n",
    "        #self.data = pd.read_csv(csv_file).iloc[:, 1]\n",
    "        self.fashion_data = torch.load(image_dir)\n",
    "        self.fashion_imgs = self.fashion_data[0]/255\n",
    "        self.fashion_labels = self.fashion_data[1]\n",
    "        self.transform = transform\n",
    "        self.nbh_size = nbh_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.fashion_labels.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #image_name = os.path.join(self.image_dir, self.image_files[index])  \n",
    "        #image = PIL.Image.open(image_name)\n",
    "        image = self.fashion_imgs[index]\n",
    "        #label = self.data[index]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        nbh_im = torch.empty((0,32)) \n",
    "        for i in range(10):\n",
    "            x1 = np.random.randint(0, images[1].shape[1]-self.nbh_size[0]-1)\n",
    "            y1 = np.random.randint(0, images[1].shape[2]-self.nbh_size[1]-1)\n",
    "        \n",
    "            x2, y2 = x1+portion_size[0], y1+portion_size[1]\n",
    "            nbh = torch.flatten(image[x1:x2,y1:y2])\n",
    "            nbh = nbh[:32]\n",
    "            nbh_im = torch.cat((nbh_im, nbh.unsqueeze(0)), dim = 0)\n",
    "        \n",
    "        return nbh_im#image #, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ac988f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Tensor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-319fc9be1903>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mtntn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m def GaussianMixNLLLoss(input: Tensor,\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mvar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Tensor' is not defined"
     ]
    }
   ],
   "source": [
    "class GaussMixNLLLoss():\n",
    "    def __init__(self):\n",
    "        tntn\n",
    "def GaussianMixNLLLoss(input: Tensor,\n",
    "    target: Tensor,\n",
    "    var: Tensor,\n",
    "    full: bool = False,\n",
    "    eps: float = 1e-6,\n",
    "    reduction: str = \"mean\",\n",
    ") -> Tensor:\n",
    "    \n",
    "    if torch.any(var < 0):\n",
    "        raise ValueError(\"var has negative entry/entries\")\n",
    "        \n",
    "    # Clamp for stability\n",
    "    var = var.clone()\n",
    "    with torch.no_grad():\n",
    "        var.clamp_(min=eps)\n",
    "    \n",
    "    loss = 0.5 * (torch.log(var) + (input - target)**2 / var)\n",
    "    \n",
    "    if reduction == 'mean':\n",
    "        return loss.mean()\n",
    "    elif reduction == 'sum':\n",
    "        return loss.sum()\n",
    "    else:\n",
    "        return loss\n",
    "    \n",
    "def GaussianMixNLLLoss(pi_s, mu, var, target):\n",
    "    GaussianNLLLoss = torch.nn.GaussianNLLLoss()\n",
    "    total_likelihood = 0\n",
    "\n",
    "    # Calculate and sum the likelihoods of each component\n",
    "    for k, pi_k in enumerate(pi_s):\n",
    "        loss = GaussianNLLLoss(mu[k], target, var[k])\n",
    "        likelihood = torch.exp(-loss)\n",
    "        total_likelihood += pi_k * likelihood\n",
    "\n",
    "    # Take the negative log to give the GMM negative log-likelihood loss\n",
    "    GMM_NLLLoss = -torch.log(total_likelihood) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b281841",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion = FashionNeihgborhoodData(image_dir='MNIST_data/FashionMNIST/processed/test.pt')#, transform=transforms.ToTensor())\n",
    "#fashion[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e8bed8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):#define neighborhood size\n",
    "    '''\n",
    "    Multilayer Perceptron.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(31, 64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64, 32),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(32, 64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64, 2),#,\n",
    "        #nn.ReLU()\n",
    "        #nn.Sigmoid()\n",
    "        \n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''Forward pass'''\n",
    "        out = self.layers(x)\n",
    "        \n",
    "        mu = torch.reshape(out[:,0],(out.shape[0],1))\n",
    "        sig = torch.reshape(torch.exp(out[:,1]),(out.shape[0],1))\n",
    "\n",
    "        out = torch.cat((mu,sig),dim=1)\n",
    "        #print(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cea83172",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fashion[7].shape\n",
    "#mlp(fashion[7][:,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d3be8210",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(fashion, batch_size=2,\n",
    "                        shuffle=True)#, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6fe8c174",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP()\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "loss_function = nn.GaussianNLLLoss(full=False, reduction='mean')\n",
    "optimizer = torch.optim.SGD(mlp.parameters(), lr=1e-4)\n",
    "#trainloader = torch.utils.data.DataLoader(train_dat, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e061bdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20 #20\n",
    "loss_vals = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e1e59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(epochs): # 5 epochs at maximum\n",
    "    \n",
    "    # Print epoch\n",
    "    print(f'Starting epoch {e+1}')\n",
    "    \n",
    "    # Set current loss value\n",
    "    current_loss = 0.0\n",
    "    \n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "      \n",
    "      # Get and prepare inputs\n",
    "        data = torch.reshape(data,(-1,32))\n",
    "        inputs, targets = data[:,:-1], data[:,-1]\n",
    "        inputs, targets = inputs.float(), targets.float()\n",
    "        targets = targets.reshape((targets.shape[0], 1))\n",
    "      \n",
    "      # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "      \n",
    "      # Perform forward pass\n",
    "        outputs = mlp(inputs)\n",
    "        mu_s = outputs[:,0]\n",
    "        sigma_s = outputs[:,1]  #sigma2 \n",
    "        #sigma_s = torch.exp(outputs[:,1])\n",
    "        #print(outputs.shape)\n",
    "      \n",
    "      # Compute loss\n",
    "        #loss = loss_function(outputs, targets)\n",
    "        loss = loss_function(mu_s, targets, sigma_s)\n",
    "      \n",
    "      # Perform backward pass\n",
    "        loss.backward()\n",
    "      \n",
    "      # Perform optimization\n",
    "        optimizer.step()\n",
    "      \n",
    "      # Print statistics\n",
    "        current_loss += loss.item()\n",
    "        \n",
    "        #if i % 500 == 0:\n",
    "        if i % 20 == 0:\n",
    "            print('Loss after mini-batch %5d: %.3f' %\n",
    "                (i + 1, current_loss / 500))\n",
    "            current_loss = 0.0\n",
    "\n",
    "  # Process is complete.\n",
    "    loss_vals.append(current_loss)\n",
    "    print('Training process has finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4911952f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b67b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install pytorch torchvision torchaudio -c pytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe17f87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(dataloader)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee240ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, data in enumerate(dataloader, 0):\n",
    "    #print(batch_idx)\n",
    "    #print(torch.reshape(data,(-1,32)).shape)\n",
    "    data = torch.reshape(data,(-1,32))\n",
    "    inputs, targets = data[:,:-1], data[:,-1]\n",
    "    #inputs, targets = inputs.float(), targets.float()\n",
    "    #print(targets.shape)\n",
    "    targets = targets.reshape((targets.shape[0], 1))\n",
    "    #print(targets.shape)\n",
    "    \n",
    "    #print(data[:,:,])\n",
    "    inp = inputs\n",
    "    print(inputs.dtype)\n",
    "    break\n",
    "    #outputs = mlp(inputs)\n",
    "    #mu_s = outputs[:,0]\n",
    "    #sigma_s = outputs[:,1] \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf005e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmmm[1].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1a6fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fashion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0030d60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = inp-0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf21da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f68540b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
