{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be01ce8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "260f362e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a152aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                                transforms.Normalize((0.5), (0.5))\n",
    "                               ])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.FashionMNIST('MNIST_data/', download = True, train = True, transform = transform)\n",
    "testset = datasets.FashionMNIST('MNIST_data/', download = True, train = False, transform = transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = 64, shuffle = True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = 64, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13c46afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "# Examine a sample\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "print(type(images))\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "565d1c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fde2020ae80>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[1].numpy().squeeze(), cmap = 'Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "257c7bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[1].numpy().squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbde0c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "542a6fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "portion_size = (10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70730c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = random.randint(0, images[1].shape[1]-portion_size[0]-1)\n",
    "y1 = random.randint(0, images[1].shape[2]-portion_size[1]-1)\n",
    "\n",
    "#x2, y2 = x1+portion_size[0]-1, y1+portion_size[1]-1\n",
    "x2, y2 = x1+portion_size[0], y1+portion_size[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "049f7efc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "915fe923",
   "metadata": {},
   "outputs": [],
   "source": [
    "part_im = images[1].numpy().squeeze()[x1:x2,y1:y2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5f1b11f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.09803921, -0.01176471,  0.39607847,  0.28627455,  0.79607844,\n",
       "        -0.42745095,  0.00392163, -0.1372549 , -0.1372549 , -0.14509803],\n",
       "       [-0.23137254,  0.00392163,  0.5921569 ,  0.19215691,  0.8745098 ,\n",
       "        -0.3333333 ,  0.04313731, -0.09019607, -0.12941176, -0.1372549 ],\n",
       "       [-0.27843136, -0.02745098,  0.81960785,  0.09019613,  0.94509804,\n",
       "        -0.31764704, -0.0745098 , -0.12156862, -0.1607843 , -0.12156862],\n",
       "       [-0.24705881, -0.16862744,  0.6313726 ,  0.05882359,  0.8980392 ,\n",
       "        -0.30196077, -0.08235294, -0.09803921, -0.17647058, -0.10588235],\n",
       "       [-0.01960784, -0.01176471,  0.67058825, -0.09803921,  0.79607844,\n",
       "        -0.24705881, -0.09019607, -0.14509803, -0.12156862, -0.09803921],\n",
       "       [-0.32549018, -0.19999999,  0.5921569 ,  0.17647064,  0.6       ,\n",
       "        -0.1607843 , -0.01176471, -0.12156862, -0.03529412, -0.01960784],\n",
       "       [-1.        , -1.        , -1.        ,  0.33333337,  0.30980396,\n",
       "        -0.20784312, -0.02745098, -0.18431371, -0.06666666,  0.00392163],\n",
       "       [-1.        , -1.        , -1.        ,  0.11372554, -0.01960784,\n",
       "        -0.0745098 , -0.05098039, -0.20784312, -0.02745098,  0.11372554],\n",
       "       [-1.        , -0.99215686, -1.        , -0.1372549 ,  0.082353  ,\n",
       "         0.02745104, -0.06666666, -0.20784312,  0.00392163,  0.20000005],\n",
       "       [-1.        , -1.        , -1.        , -0.38823527,  0.05098045,\n",
       "         0.17647064, -0.12156862, -0.20784312,  0.0196079 ,  0.26274514]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e570bb62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 20, 3, 13)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1,x2,y1,y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd24a143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fde2048d730>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(part_im, cmap = 'Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29a52917",
   "metadata": {},
   "outputs": [],
   "source": [
    "part_im = part_im.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86e688e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part_im[:95].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90642e14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20ec6a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3668ea10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbc2a98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56b26913",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make dataloader that can sample part of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92e08b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make custum gaussian mixture NLL loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6a4546db",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_imgs = torch.load('MNIST_data/FashionMNIST/processed/test.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b130300b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "08705077",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionNeihgborhoodData(Dataset):\n",
    "\n",
    "    def __init__(self, image_dir, transform=None, nbh_size=(4,9)):#csv_file,root,\n",
    "        #self.root = root\n",
    "        self.image_dir = image_dir\n",
    "        #self.image_files = os.listdir(image_dir)\n",
    "        #self.data = pd.read_csv(csv_file).iloc[:, 1]\n",
    "        self.fashion_data = torch.load(image_dir)\n",
    "        self.fashion_imgs = self.fashion_data[0]/255\n",
    "        self.fashion_labels = self.fashion_data[1]\n",
    "        self.transform = transform\n",
    "        self.nbh_size = nbh_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.fashion_labels.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #image_name = os.path.join(self.image_dir, self.image_files[index])  \n",
    "        #image = PIL.Image.open(image_name)\n",
    "        image = self.fashion_imgs[index]\n",
    "        #label = self.data[index]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        nbh_im = torch.empty((0,32)) \n",
    "        for i in range(10):\n",
    "            x1 = np.random.randint(0, images[1].shape[1]-self.nbh_size[0]-1)\n",
    "            y1 = np.random.randint(0, images[1].shape[2]-self.nbh_size[1]-1)\n",
    "        \n",
    "            x2, y2 = x1+portion_size[0], y1+portion_size[1]\n",
    "            nbh = torch.flatten(image[x1:x2,y1:y2])\n",
    "            nbh = nbh[:32]\n",
    "            nbh_im = torch.cat((nbh_im, nbh.unsqueeze(0)), dim = 0)\n",
    "        \n",
    "        return nbh_im#image #, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b281841",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion = FashionNeihgborhoodData(image_dir='MNIST_data/FashionMNIST/processed/test.pt')#, transform=transforms.ToTensor())\n",
    "#fashion[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e8bed8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):#define neighborhood size\n",
    "    '''\n",
    "    Multilayer Perceptron.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(31, 64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64, 32),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(32, 64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64, 2),#,\n",
    "        #nn.ReLU()\n",
    "        #nn.Sigmoid()\n",
    "        \n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''Forward pass'''\n",
    "        out = self.layers(x)\n",
    "        \n",
    "        mu = torch.reshape(out[:,0],(out.shape[0],1))\n",
    "        sig = torch.reshape(torch.exp(out[:,1]),(out.shape[0],1))\n",
    "\n",
    "        out = torch.cat((mu,sig),dim=1)\n",
    "        #print(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d3be8210",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(fashion, batch_size=2,\n",
    "                        shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6fe8c174",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP()\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "loss_function = nn.GaussianNLLLoss(full=False, reduction='mean')\n",
    "optimizer = torch.optim.SGD(mlp.parameters(), lr=1e-4)\n",
    "#trainloader = torch.utils.data.DataLoader(train_dat, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e061bdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20 #20\n",
    "loss_vals = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e1e59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(epochs): # 5 epochs at maximum\n",
    "    \n",
    "    # Print epoch\n",
    "    print(f'Starting epoch {e+1}')\n",
    "    \n",
    "    # Set current loss value\n",
    "    current_loss = 0.0\n",
    "    \n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "      \n",
    "      # Get and prepare inputs\n",
    "        data = torch.reshape(data,(-1,32))\n",
    "        inputs, targets = data[:,:-1], data[:,-1]\n",
    "        inputs, targets = inputs.float(), targets.float()\n",
    "        targets = targets.reshape((targets.shape[0], 1))\n",
    "      \n",
    "      # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "      \n",
    "      # Perform forward pass\n",
    "        outputs = mlp(inputs)\n",
    "        mu_s = outputs[:,0]\n",
    "        sigma_s = outputs[:,1]  #sigma2 \n",
    "        #sigma_s = torch.exp(outputs[:,1])\n",
    "        #print(outputs.shape)\n",
    "      \n",
    "      # Compute loss\n",
    "        #loss = loss_function(outputs, targets)\n",
    "        loss = loss_function(mu_s, targets, sigma_s)\n",
    "      \n",
    "      # Perform backward pass\n",
    "        loss.backward()\n",
    "      \n",
    "      # Perform optimization\n",
    "        optimizer.step()\n",
    "      \n",
    "      # Print statistics\n",
    "        current_loss += loss.item()\n",
    "        \n",
    "        #if i % 500 == 0:\n",
    "        if i % 20 == 0:\n",
    "            print('Loss after mini-batch %5d: %.3f' %\n",
    "                (i + 1, current_loss / 500))\n",
    "            current_loss = 0.0\n",
    "\n",
    "  # Process is complete.\n",
    "    loss_vals.append(current_loss)\n",
    "    print('Training process has finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4911952f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b67b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install pytorch torchvision torchaudio -c pytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe17f87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(dataloader)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ee240ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.1686, 0.5725,  ..., 0.4549, 0.2000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.2471, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.1686, 0.4431, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.6902, 0.7176, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.6784, 0.6902, 0.0000],\n",
      "        [0.0000, 0.0000, 0.7176,  ..., 0.7765, 0.6745, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, data in enumerate(dataloader, 0):\n",
    "    #print(batch_idx)\n",
    "    #print(torch.reshape(data,(-1,32)).shape)\n",
    "    data = torch.reshape(data,(-1,32))\n",
    "    inputs, targets = data[:,:-1], data[:,-1]\n",
    "    inputs, targets = inputs.float(), targets.float()\n",
    "    #print(targets.shape)\n",
    "    targets = targets.reshape((targets.shape[0], 1))\n",
    "    #print(targets.shape)\n",
    "    \n",
    "    #print(data[:,:,])\n",
    "    print(inputs)\n",
    "    break\n",
    "    #outputs = mlp(inputs)\n",
    "    #mu_s = outputs[:,0]\n",
    "    #sigma_s = outputs[:,1] \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf005e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmmm[1].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1a6fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fashion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf21da2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
